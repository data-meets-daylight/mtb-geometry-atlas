# clustering_data$cluster3 <- factor(kmTest3$cluster)
#
# # Plot PC1 vs PC2
# kmplot_12 <- ggplot(clustering_data, aes(PC1, PC2, color = cluster3)) +
#   geom_point(size = 2) +
#   theme_minimal() +
#   ggtitle("k = 3 clusters (PC1 vs PC2)")
#
# # Plot PC1 vs PC3
# kmplot_13 <- ggplot(clustering_data, aes(PC1, PC3, color = cluster3)) +
#   geom_point(size = 2) +
#   theme_minimal() +
#   ggtitle("k = 3 clusters (PC1 vs PC3)")
#
# # Plot PC2 vs PC3
# kmplot_23 <- ggplot(clustering_data, aes(PC2, PC3, color = cluster3)) +
#   geom_point(size = 2) +
#   theme_minimal() +
#   ggtitle("k = 3 clusters (PC2 vs PC3)")
#
#
# grid.arrange(kmplot_12, kmplot_13, kmplot_23, nrow = 2)
set.seed(123)
X2 <- clustering_data[, 1:2]
X3 <- clustering_data[, 1:3]
km2 <- kmeans(X2, centers = 3, nstart = 50)
km3 <- kmeans(X3, centers = 3, nstart = 50)
library(cluster)
sil2 <- silhouette(km2$cluster, dist(X2))
sil3 <- silhouette(km3$cluster, dist(X3))
mean(sil2[, 3]); mean(sil3[, 3])
library(plotly)
plot_ly(
data = clustering_data,
x = ~PC1, y = ~PC2, z = ~PC3,
color = ~factor(k4$cluster),
colors = c("#E41A1C", "#377EB8", "#4DAF4A"),
type = "scatter3d",
mode = "markers"
) %>%
layout(title = "3D PCA space - k = 3 clusters")
# mixed_df: data.frame with numeric columns and categorical columns as factors
id_cols <- c("Brand", "Model", "Year", "Wheel.Size") # categorical columns in mtbgeo
# id_cols <- c("Brand", "Model", "Wheel.Size") # categorical columns in mtbgeo
mixed_df <- cbind(
mtbgeo[, intersect(id_cols, names(mtbgeo)), drop = FALSE],
as.data.frame(mtbgeo[, strong_vars])
)
head(mixed_df)
mixed_df$Brand = as.factor(mixed_df$Brand) # need to turn these categorical variables into clusters
mixed_df$Model = as.factor(mixed_df$Model)
mixed_df$Year = as.factor(mixed_df$Year)
mixed_df$Wheel.Size = as.factor(mixed_df$Wheel.Size)
head(mixed_df)
set.seed(123)
# k-prototypes (handles mixed types)
kmix <- kproto(mixed_df, k = 4, lambda = NULL, nstart = 50)
# lambda = NULL => auto-estimated balance between numeric and categorical parts
kmix$centers        # data frame: numeric columns are means; factors are modes
kmix$lambda            # numeric↔categorical balance used
kmix$size              # cluster sizes
kmix$withinss          # within-cluster dissimilarity per cluster
kmix$tot.withinss      # total within-cluster dissimilarity
# summary(kmix)
library(clustMixType)
library(dplyr)
library(ggplot2)
library(cluster)   # for optional silhouette
# Ensure types are correct
mixed_df[] <- lapply(mixed_df, function(x) if (is.character(x)) factor(x) else x)
kproto_sweep <- function(df, k_range = 1:10, nstart = 30, seed = 123, do_silhouette = TRUE) {
set.seed(seed)
# Precompute Gower once for silhouettes (optional)
d_gower <- if (do_silhouette) daisy(df, metric = "gower") else NULL
res <- lapply(k_range, function(k) {
fit <- kproto(df, k = k, nstart = nstart)
sil_mean <- if (!is.null(d_gower) && k > 1)
mean(silhouette(as.integer(fit$cluster), d_gower)[,3]) else NA_real_
data.frame(
k             = k,
tot_withinss  = fit$tot.withinss,     # k-prototypes objective (lower is better)
lambda        = fit$lambda,           # numeric↔categorical balance used
sil_mean      = sil_mean
)
})
out <- bind_rows(res)
# “Explained dissimilarity” relative to k=1 (acts like a pseudo R^2)
out <- out %>%
mutate(
tot_withinss_k1 = first(tot_withinss),
explained = 1 - tot_withinss / tot_withinss_k1
)
out
}
# Run the sweep
ks <- 1:10
sweep_df <- kproto_sweep(mixed_df, k_range = ks, nstart = 50, do_silhouette = TRUE)
# Elbow-style “scree” for k-prototypes
p1 <- ggplot(sweep_df, aes(k, tot_withinss)) +
geom_line() + geom_point() +
labs(title = "k-prototypes elbow (total within-cluster dissimilarity)",
x = "k", y = "Total withinss (lower is better)")
knitr::opts_chunk$set(echo = TRUE)
#Install and load packages chunk
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)
library(DataExplorer)
library(MVN)
library(corrplot)
library(psych)
library(ggbiplot)
library(grDevices)
library(devtools)
library(factoextra)
library(gridExtra)
library(clustMixType)
library(cluster)
library(ggalluvial)
# library(plotly) # for 3d plot, not used rn
#Import data
allbikegeo <- read.csv("Data/geometrics.mtb-news.de.csv", sep = ";", stringsAsFactors = FALSE)
#Filter to Mountain bikes only
mtbgeo_only <- subset(allbikegeo, Category == "Mountain")
#Filter to remove 26" wheels
mtbgeo_only <- subset(mtbgeo_only, !grepl("26", Wheel.Size))
#Convert 0 Year to NA (for later removal)
mtbgeo_only$Year <- as.integer(mtbgeo_only$Year)
mtbgeo_only$Year[mtbgeo_only$Year == 0] <- NA
#Replace NA for rear suspension with 0 (assume hardtail)
mtbgeo_only$Suspension.Travel..rear. <- as.numeric(mtbgeo_only$Suspension.Travel..rear.)
mtbgeo_only$Suspension.Travel..rear.[is.na(mtbgeo_only$Suspension.Travel..rear.)] <- 0
#Remove rows with NA in 'Suspension.Travel..front.'
mtbgeo_only$Suspension.Travel..front. <- as.numeric(mtbgeo_only$Suspension.Travel..front.)
mtbgeo_only <- mtbgeo_only[!is.na(mtbgeo_only$Suspension.Travel..front.), ]
#Drop columns with too many missing values (> 1000)
keep_cols <- colSums(is.na(mtbgeo_only)) <= 1000
mtbgeo_reduced <- mtbgeo_only[, keep_cols]
#remove unneeded columns
mtbgeo_reduced <- mtbgeo_reduced[, !(names(mtbgeo_reduced) %in% c("Frame.Config", "URL", "Category"))]
#Keep only Medium-sized bikes to allow fair comparison of geometry
mtbgeo_medium <- mtbgeo_reduced[mtbgeo_reduced$Frame.Size %in% c("M", "Medium"), ]
#remove all rows that have any NA's in numeric/integer columns
num_cols <- sapply(mtbgeo_medium, function(x) is.numeric(x) || is.integer(x))
vars_to_check <- names(mtbgeo_medium)[num_cols]
mtbgeo_clean <- mtbgeo_medium[complete.cases(mtbgeo_medium[, vars_to_check]),]
#rename dataframe and check
mtbgeo <- mtbgeo_clean
# str(mtbgeo)
# anyNA(mtbgeo)
#Create numeric only dataframe
num_vars <- sapply(mtbgeo, is.numeric)
# str(mtbgeo[, num_vars])
#Create numeric only without suspension and Year vars dataframe
drop_vars <- c("Year", "Suspension.Travel..rear.", "Suspension.Travel..front.")
geo_vars <- sapply(mtbgeo, is.numeric) & !(names(mtbgeo) %in% drop_vars)
str(mtbgeo[, geo_vars])
mtbgeo_zscores <- mtbgeo   #make copy
mtbgeo_zscores[, geo_vars] <- scale(mtbgeo_zscores[, geo_vars]) #standardise geo_vars
str(mtbgeo_zscores)
# make y label groups for validation ("Cross-country", "Trail", "Enduro",  "Downhill")
mtbgeo_groups <- mtbgeo %>%
mutate(
Category = case_when(
# Downhill: both ends ≥ 180 (must have rear)
!is.na(Suspension.Travel..rear.) &
Suspension.Travel..front. >= 180 & Suspension.Travel..rear. >= 180 ~ "Downhill",
# Enduro: rear 150–180 AND front 140–190 (must have rear)
!is.na(Suspension.Travel..rear.) &
Suspension.Travel..rear. >= 145 & Suspension.Travel..rear. <= 180 &
Suspension.Travel..front. >= 140 & Suspension.Travel..front. <= 190 ~ "Enduro",
# Cross-country: front 100–120 AND (no rear OR rear ≤ 120)
Suspension.Travel..front. >= 100 & Suspension.Travel..front. <= 120 &
(is.na(Suspension.Travel..rear.) | Suspension.Travel..rear. <= 130) ~ "Cross-country",
# Trail: front 121–160 AND rear ≤ 150 (must have rear)
!is.na(Suspension.Travel..rear.) &
Suspension.Travel..front. >= 121 & Suspension.Travel..front. <= 160 &
Suspension.Travel..rear. <= 150 ~ "Trail",
TRUE ~ "Other"
)
)
# order
mtbgeo_groups$Category <- factor(mtbgeo_groups$Category, levels = c("Cross-country", "Trail", "Enduro",  "Downhill"))
# Count bikes in each group
mtbgeo_groups %>%
count(Category)
# View(mtbgeo_groups[mtbgeo_groups$Category == "Other", ])
# Count bikes per category
cat_counts <- mtbgeo_groups %>%
count(Category)
pal_geo <- c("Downhill"="purple",
"Enduro"="mediumturquoise",
"Trail"="yellowgreen",
"Cross-country"="#F8766D")
# Plot number bikes per category
ggplot(cat_counts, aes(x = Category, y = n, fill = Category)) +
geom_col(width = 0.7) +
geom_text(aes(label = n), vjust = -0.4, size = 4) +
scale_fill_manual(values = pal_geo, guide = "none") +
labs(
title = "Number of Bikes per Category",
x = "Category",
y = "Count of Bikes"
) +
theme_classic(base_size = 13) +
theme(
legend.position = "none",
plot.title = element_text(face = "bold", hjust = 0.5)
)
outlier_rows <- apply(abs(mtbgeo_zscores[, geo_vars]), 1, max) > 7  # Flag rows where any geometry z-score exceeds our threshold
print(mtbgeo[outlier_rows, ])    # View the outliers (without standardised values)
# View((mtbgeo[outlier_rows, ]))
# remove above observations
mtbgeo <- mtbgeo[!outlier_rows, ]
mtbgeo_zscores <- mtbgeo_zscores[!outlier_rows, ]
mtbgeo_groups <- mtbgeo_groups[!outlier_rows, ]
nrow(mtbgeo)
nrow(mtbgeo_groups)
Matrix_mtbgeo_z <- as.matrix(mtbgeo_zscores[, geo_vars])
# mvn(Matrix_mtbgeo_z, mvn_test = "royston", univariate_test = "AD") #or mvn_test = "hz" or "royston" or
multivariate_diagnostic_plot(Matrix_mtbgeo_z)
univariate_diagnostic_plot(Matrix_mtbgeo_z, type = "boxplot")
# Check for outliers shown with mahalanobis and remove outlier (2022 Lapace Prorace)
md <- mahalanobis(Matrix_mtbgeo_z,
center = colMeans(Matrix_mtbgeo_z),
cov = cov(Matrix_mtbgeo_z))
sqrt(max(md))
maxmala <- which.max(md)
mtbgeo[which.max(md), ]
mtbgeo <- mtbgeo[-maxmala, ]  # remove above observation
mtbgeo_zscores <- mtbgeo_zscores[-maxmala, ]  # remove above observation
mtbgeo_groups <- mtbgeo_groups[-maxmala, ]  # remove above observation
# column means
(colMeans(mtbgeo[, geo_vars]))
# (View(cov(mtbgeo[, geo_vars])))
# Check distributions of each variable
vars <- c(names(mtbgeo)[geo_vars],
"Suspension.Travel..rear.",
"Suspension.Travel..front.")
df_long <- mtbgeo[, vars] |>
pivot_longer(everything(), names_to = "var", values_to = "val") # Long format for faceting
n_geo <- length(geo_vars)
pal_geo <- grDevices::hcl.colors(n_geo, palette = "viridis")
pal_susp <- grDevices::hcl.colors(2, palette = "reds")
pal <- c(pal_geo, pal_susp)
ggplot(df_long, aes(x = val, fill = var)) +
geom_density(alpha = 0.7) +
facet_wrap(~ var, scales = "free", ncol = 3) +
scale_fill_manual(values = pal, guide = "none") +
labs(title = "Distribution of Geometry Variables + Suspension",
x = "Geometry Variables",
y = "Density") +
theme_classic() +
theme(
plot.title = element_text(hjust = 0.5, color = "slateblue4", size = 16),
axis.title.x = element_text(size = 14),
axis.title.y = element_text(size = 14)
)
# Correlation matrix
Matrix_mtbgeo <- as.matrix(mtbgeo[, geo_vars])
round(cor(Matrix_mtbgeo), 4)
# Correlation plot
corrplot(cor(Matrix_mtbgeo), method = "color", type = "upper",
tl.col = "black", tl.srt = 45, addCoef.col = "black",
number.cex = 0.6)  # correlation heatmap
# Use MSA to check suitable correlations for PCA (see report PCA references)
cortest.bartlett(cor(mtbgeo[, geo_vars]), n = nrow(mtbgeo[, geo_vars]))
KMO(cor(mtbgeo[, geo_vars]))
# remove weak MSA variables < 0.4
weak_vars <- c("Chainstay.Length", "STR", "Stack")
# check correlation and MSA of strong MSA variables < 0.48
strong_vars <- sapply(mtbgeo, is.numeric) &
!(names(mtbgeo) %in% c("Year",
"Suspension.Travel..rear.",
"Suspension.Travel..front.",
weak_vars))
KMO(cor(mtbgeo[, strong_vars]))
Matrix_mtbstrong <- as.matrix(mtbgeo[, strong_vars])
corrplot(cor(Matrix_mtbstrong), method = "color", type = "upper",
tl.col = "black", tl.srt = 45, addCoef.col = "black",
number.cex = 0.6)  # correlation heatmap
mtbgeo[strong_vars]
# outputs a PDF to file of scatterplots of all combinations of variables to check linearity
vars <- names(mtbgeo)[strong_vars]
pdf("scatterpairs_all.pdf", width = 6, height = 5)
# loop over all pairs
cmb <- combn(vars, 2, simplify = FALSE)
for (xy in cmb) {
x <- xy[1]; y <- xy[2]
plot(mtbgeo[[x]], mtbgeo[[y]],
xlab = x, ylab = y, pch = 20, col = "grey40",
main = paste(y, "vs", x))
abline(lm(mtbgeo[[y]] ~ mtbgeo[[x]]), lty = 2, col = "black")  # visual linear fit
}
dev.off()
# Perform PCA:
pca <- princomp(mtbgeo[, strong_vars], #PCA
cor = TRUE)
pca$loadings
summary(pca)                 # Std. dev, Proportion of Var, Cumulative Var
eigvals <- pca$sdev^2        # eigenvalues λ_i
eigvals
# Select n components
pve <- eigvals / sum(eigvals)  # proportion of total variance
round(cbind(Eigenvalue = eigvals,
Proportion = pve,
CumProp = cumsum(pve)), 3)
plot(pca, type = "l", main = "Scree Plot of Principal Components")
## Bar scree (optional) + Kaiser line at 1 (on correlation, λ=1 rule)
barplot(eigvals, names.arg = paste0("PC", seq_along(eigvals)),
main = "Eigenvalues (Bar Scree)", ylab = "Eigenvalue")
abline(h = 1, col = 2, lty = 2)
summary(pca)
loadings <- pca$loadings
print(loadings)
K <- which(cumsum(pve) >= 0.80)[1]   # first K with ≥80% cumulative variance
K
# pca scores for each bike
id_cols <- c("Brand", "Model", "Year")
scores_df <- cbind(
mtbgeo[, intersect(id_cols, names(mtbgeo)), drop = FALSE],
as.data.frame(pca$scores)
)
head(scores_df)
# Biplot using pseudo-labelled colours with 50% probability ellipses, showing variable orthogonality
mtbgeo_groups$Category <- factor(mtbgeo_groups$Category, levels = c("Cross-country", "Trail", "Enduro",  "Downhill"))
ggbiplot(pca,
obs.scale = 2,
var.scale = 2,
point.size = 1.2,
varname.adjust = 2,
groups = mtbgeo_groups$Category,
ellipse = TRUE,
ellipse.linewidth = 0.2,
circle = FALSE,
ellipse.prob = .5) +
theme_classic() +
labs(title = "PCA biplot with bike categories (50% probability ellipses)") +
theme(legend.direction = 'horizontal',
legend.position = 'top')
# put the pca scores into a dataframe
clustering_data <- as.data.frame(pca$scores)
colnames(clustering_data) <- c("PC1", "PC2", "PC3", "PC4")
clustering_sub2 <- clustering_data[ , 1:2]
clustering_sub3 <- clustering_data[ , 1:3]
clustering_sub4 <- clustering_data[ , 1:4]
# do some sort of test to figure out what k should be
set.seed(123)
( sub2_p1 <- fviz_nbclust(clustering_sub2, kmeans, method = "wss") )
( sub2_p2 <- fviz_nbclust(clustering_sub2, kmeans, method = "silhouette") )
( sub2_p3 <- fviz_nbclust(clustering_sub2, kmeans, method = "gap_stat") )
# fviz_nbclust(clustering_sub3, kmeans, method = "wss")
# fviz_nbclust(clustering_sub4, kmeans, method = "wss")
grid.arrange(grobs = c(sub2_p1, sub2_p2), ncol=2)
#Anything from 3 to 6 clusters is optimal. I will do clustering and print plots with 3, 4, 5 and 6 clusters and then see which one looks best.
# Check to see what data looks like before being clustered, guess what points would realistically be grouped together
plot(clustering_sub2$PC1, clustering_sub2$PC2)
obs_kclusts <- function(k, clust_data) {
kmTest <- kmeans(clust_data, centers=k, nstart = 20)
ratio <- kmTest$betweenss/kmTest$totss
print(paste("ratio for",k,"clusters:", ratio))
return(kmTest)
}
print_kclusts <- function(kmTest, clust_data) {
plot_k <- fviz_cluster(kmTest, geom = "point", data = clust_data, choose.vars = c("PC1", "PC2")) +
ggtitle(paste("k =", k)) + theme_minimal()
plot_k
}
clustering_data <- clustering_sub2
n <- 7  # max number of clusters to test
results <- list()
for (k in 2:n) {
results[[paste0("k", k)]] <- obs_kclusts(k, clustering_data)
}
lapply(results, print_kclusts, clustering_data)
plots <- list()
for (k in 2:n) {
kmTest <- kmeans(clustering_sub2, centers = k, nstart = 20)
plots[[paste0("k", k)]] <- fviz_cluster(kmTest, geom = "point", data = clustering_sub2, choose.vars = c("PC1", "PC2")) + ggtitle(paste("k =", k))
}
grid.arrange(grobs = plots, ncol = 3)
bike_confusion_table <- function(data, cluster_data) {
data_clone <- data
data_clone$cluster  <- factor(cluster_data$cluster)
data_clone$Category <- factor(mtbgeo_groups$Category, levels = c("Cross-country", "Trail", "Enduro",  "Downhill"))
# confusion-style table
tab <- table(Cluster = data_clone$cluster, Category = data_clone$Category)
prop.table(tab, 1)  # row %: composition of each cluster
return(tab)
}
bike_sankey <- function(table, plot_title) {
df_alluv <- as.data.frame(table) %>% as_tibble()
ggplot(df_alluv, aes(axis1 = Category, axis2 = Cluster, y = Freq)) +
geom_alluvium(aes(fill = Category), width = 0.1, alpha = 0.6) +
geom_stratum(aes(fill = Category), width = 0.05, alpha=0.3) +
# scale_fill_brewer(palette = "Dark2", name = "Category") +
geom_text(stat = "stratum", aes(label = after_stat(stratum)), hjust = 0, nudge_x = 0.03) +
labs(title = plot_title, y = "", subtitle = "Flow Weight =  No. of Bikes") +
theme_void() + theme(axis.text.y  = element_blank(), axis.text.x  = element_blank())
}
(table1 <- bike_confusion_table(clustering_data, results$k6))
prop.table(table1, 1)
bike_sankey(table1, "Bike Category → 6 k-means Clusters")
# # This is for the wrong clusters atm, k4 is for 2 PCs but is being plotted for sub3 (3 PCs)
#
# plot_ly(data = clustering_sub3, x = ~PC1, y = ~PC2, z = ~PC3, color = ~factor(k4$cluster),
#   colors = c("#E41A1C", "#377EB8", "#4DAF4A"), type = "scatter3d", mode = "markers") %>%
#   layout(title = "3D PCA space - k = 3 clusters")
# SVM: multi-class classification on numeric geometry-only features
# Extra packages required for this SVM section
library(e1071)
library(caret)
library(lattice)
set.seed(1234)
# Build labelled data frame: X = geometry vars only, y = Category from mtbgeo_groups
feature_names <- names(mtbgeo)[geo_vars]
svm_df <- mtbgeo[, feature_names, drop = FALSE] %>%
mutate(Category = factor(mtbgeo_groups$Category))
# Stratified train/test split as classes are imbalanced and we need them all represented in train and test sets
idx <- caret::createDataPartition(svm_df$Category, p = 0.7, list = FALSE)
train <- svm_df[idx, ]
test  <- svm_df[-idx, ]
# Compute class weights to address imbalance (median frequency scaling)
freq <- table(train$Category)
class_wts <- as.numeric(median(freq) / freq)
names(class_wts) <- names(freq)
freq
# Hyperparameter tuning (radial kernel)
gamma_grid <- 2^(-9:-1)     # reasonable range for gamma (RBF width)
cost_grid  <- 2^(-1:9)      # reasonable range for C (regularisation)
# try every (C, gamma) pair on 5 fold CV on training data
tuned <- e1071::tune.svm(
x = train[, feature_names],
y = train$Category,
kernel = "radial",
gamma = gamma_grid,
cost  = cost_grid,
class.weights = class_wts,
scale = TRUE,                          # safe standardisation inside svm
tunecontrol = tune.control(cross = 5)  # 5-fold CV
)
# note to team: this will take a bit to find best
best <- tuned$best.model  # gets best (C, gamma) found by CV
best
best$cost; best$gamma      # confirm what's in the final model
# Test-set predictions
pred <- predict(best, newdata = test[, feature_names])
# Confusion matrix
cm <- caret::confusionMatrix(pred, test$Category)
cm
# Per-class precision/recall/F1
per_class_metrics <- {
lev <- levels(test$Category)
res <- lapply(lev, function(l) {
tp <- sum(test$Category == l & pred == l)
fp <- sum(test$Category != l & pred == l)
fn <- sum(test$Category == l & pred != l)
precision <- ifelse(tp + fp == 0, NA, tp / (tp + fp))
recall    <- ifelse(tp + fn == 0, NA, tp / (tp + fn))
f1        <- ifelse(
is.na(precision) | is.na(recall) | precision + recall == 0,
NA,
2 * precision * recall / (precision + recall)
)
data.frame(class = l, precision, recall, f1)
})
do.call(rbind, res)
}
accuracy <- mean(pred == test$Category)
print(per_class_metrics)
# Confusion heatmap
cm_df <- as.data.frame(table(Truth = test$Category, Pred = pred))
ggplot(cm_df, aes(x = Pred, y = Truth, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), size = 4) +
labs(title = "SVM confusion matrix (test set)", x = "Predicted", y = "True") +
theme_classic(base_size = 13) +
scale_fill_gradient(name = "Count", low = "grey95", high = "steelblue4")
# PCA on train dataset only
Xtr <- train[, feature_names]
pcs <- princomp(Xtr, cor = TRUE, scores = FALSE)
# choose k PCs (e.g. keep 95% variance)
var_expl <- pcs$sdev^2 / sum(pcs$sdev^2)
k <- which(cumsum(var_expl) >= 0.95)[1]
k <- 2
# project train/test to PC space
train_scores <- as.data.frame(predict(pcs, newdata = Xtr)[, 1:k])
test_scores  <- as.data.frame(predict(pcs, newdata = test[, feature_names])[, 1:k])
train_scores$Category <- train$Category
test_scores$Category  <- test$Category
# Train SVM on PC1, PC2
svm_pca <- e1071::svm(Category ~ ., data = {
sc <- as.data.frame(predict(pcs, Xtr)[, 1:2])
sc$Category <- train$Category
sc
}, kernel = "radial", gamma = best$gamma, cost = best$cost,
class.weights = class_wts, scale = TRUE)
# Decision regions grid
ts2 <- as.data.frame(predict(pcs, test[, feature_names])[, 1:2])
names(ts2) <- c("Comp.1","Comp.2")
rng1 <- range(ts2$Comp.1); rng2 <- range(ts2$Comp.2)
grid <- expand.grid(`Comp.1` = seq(rng1[1], rng1[2], length.out = 200),
`Comp.2` = seq(rng2[1], rng2[2], length.out = 200))
grid$pred <- predict(svm_pca, grid)
ggplot() +
geom_raster(data = grid, aes(`Comp.1`, `Comp.2`, fill = pred), alpha = 0.25) +
geom_point(data = transform(ts2, Category = test$Category),
aes(`Comp.1`, `Comp.2`, colour = Category), size = 1.8) +
labs(title = "SVM decision regions in PCA space") +
theme_classic(base_size = 13) +
guides(fill = "none")
